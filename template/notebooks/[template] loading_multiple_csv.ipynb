{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87008881",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-and-concatenating-multiple-CSV-files\" data-toc-modified-id=\"Reading-and-concatenating-multiple-CSV-files-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Reading and concatenating multiple CSV files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-in-relevant-libraries\" data-toc-modified-id=\"Load-in-relevant-libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load in relevant libraries</a></span></li></ul></li><li><span><a href=\"#Reading-CSV-files-from-a-folder\" data-toc-modified-id=\"Reading-CSV-files-from-a-folder-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reading CSV files from a folder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-glob-to-get-a-list-of-file-names\" data-toc-modified-id=\"Using-glob-to-get-a-list-of-file-names-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using glob to get a list of file names</a></span></li><li><span><a href=\"#Using-os.listdir-or-glob.glob-with-regex\" data-toc-modified-id=\"Using-os.listdir-or-glob.glob-with-regex-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Using os.listdir or glob.glob with regex</a></span></li></ul></li><li><span><a href=\"#Read-in-the-files-from-the-list-of-filepaths-and-concatenate\" data-toc-modified-id=\"Read-in-the-files-from-the-list-of-filepaths-and-concatenate-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Read in the files from the list of filepaths and concatenate</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-comprehension\" data-toc-modified-id=\"List-comprehension-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>List comprehension</a></span></li><li><span><a href=\"#Loop\" data-toc-modified-id=\"Loop-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Loop</a></span></li></ul></li><li><span><a href=\"#Loading-data-from-URL\" data-toc-modified-id=\"Loading-data-from-URL-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Loading data from URL</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53642569",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <span style=\"font-size:20px\">&#9888;</span> <span style=\"font-size:16px\">This is a read-only notebook! If you want to make and save changes, save a copy by clicking on <b>File</b> &#8594; <b>Save a copy</b>. If this is already a copy, you can delete this cell.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a076a",
   "metadata": {},
   "source": [
    "# Reading and concatenating multiple CSV files\n",
    "\n",
    "This Jupyter Notebook shows you how to read all CSV files from a folder or a list of locations (files or URLs), generating a pandas dataframe with all the data and writes it to a csv file.\n",
    "\n",
    "It also generates two additional columns: source filename, and time of loading. This allows subsequent data diagnostics to be done to identify abnormalities in specific files.\n",
    "\n",
    "We show simple examples with code directly in the notebook, and then provide re-usable functions with more advanced capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b3c3c",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#Reading-and-concatenating-multiple-CSV-files\" data-toc-modified-id=\"Reading-and-concatenating-multiple-CSV-files-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Reading and concatenating multiple CSV files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-in-relevant-libraries\" data-toc-modified-id=\"Load-in-relevant-libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load in relevant libraries</a></span></li></ul></li><li><span><a href=\"#Reading-CSV-files-from-a-folder\" data-toc-modified-id=\"Reading-CSV-files-from-a-folder-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reading CSV files from a folder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-glob-to-get-a-list-of-file-names\" data-toc-modified-id=\"Using-glob-to-get-a-list-of-file-names-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using glob to get a list of file names</a></span></li><li><span><a href=\"#Using-os.listdir-or-glob.glob-with-regex\" data-toc-modified-id=\"Using-os.listdir-or-glob.glob-with-regex-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Using os.listdir or glob.glob with regex</a></span></li></ul></li><li><span><a href=\"#Read-in-the-files-from-the-list-of-filepaths-and-concatenate\" data-toc-modified-id=\"Read-in-the-files-from-the-list-of-filepaths-and-concatenate-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Read in the files from the list of filepaths and concatenate</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-comprehension\" data-toc-modified-id=\"List-comprehension-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>List comprehension</a></span></li><li><span><a href=\"#Loop\" data-toc-modified-id=\"Loop-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Loop</a></span></li></ul></li><li><span><a href=\"#Loading-data-from-URL\" data-toc-modified-id=\"Loading-data-from-URL-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Loading data from URL</a></span></li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3b992",
   "metadata": {},
   "source": [
    "## Load in relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54c982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020984d",
   "metadata": {},
   "source": [
    "# Reading CSV files from a folder\n",
    "\n",
    "We show two approaches: \n",
    "* Using the 'glob.glob' function to get a list of all the CSV files in a folder. The glob function can also be used with unix patterns (https://docs.python.org/3/library/glob.html)\n",
    "* Using the 'os.listdir' function to get a list of files, and regex expressions for complex patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f6b68",
   "metadata": {},
   "source": [
    "## Using glob to get a list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f72024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_input/csv_folder_1\\\\20180913_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20181022_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190102_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190420_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200211_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200512_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200627_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200711_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200828_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210617_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210801_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220130_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220310_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220608_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220621_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20221021_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230128_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230309_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230312_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230425_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_0.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_1.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_10.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_11.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_12.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_13.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_14.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_15.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_16.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_17.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_18.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_19.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_2.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_3.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_4.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_5.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_6.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_7.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_8.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_9.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_in_folder = glob.glob(\"sample_input/csv_folder_1/*.csv\")   # the asterix * indicates wildcard\n",
    "all_csv_in_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56798281",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_input/csv_folder_1\\\\20180913_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20181022_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190102_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190420_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200211_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200512_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200627_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200711_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200828_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210617_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210801_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220130_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220310_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220608_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220621_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20221021_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230128_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230309_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230312_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230425_sample_file.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get files that satisfy a certain pattern\n",
    "subset_csv_in_folder = glob.glob(\"sample_input/csv_folder_1/*_sample_file.csv\")   # the asterix * indicates wildcard\n",
    "subset_csv_in_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c0654e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_input/csv_folder_1\\\\20180913_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20181022_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190102_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20190420_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200211_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200512_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200627_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200711_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20200828_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210617_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20210801_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220130_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220310_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220608_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20220621_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20221021_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230128_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230309_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230312_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\20230425_sample_file.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_0.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_1.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_10.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_11.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_12.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_13.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_14.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_15.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_16.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_17.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_18.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_19.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_2.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_3.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_4.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_5.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_6.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_7.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_8.csv',\n",
       " 'sample_input/csv_folder_1\\\\diff_file_9.csv',\n",
       " 'sample_input/csv_folder_2\\\\zip_0.zip',\n",
       " 'sample_input/csv_folder_2\\\\zip_1.zip',\n",
       " 'sample_input/csv_folder_2\\\\zip_2.zip',\n",
       " 'sample_input/csv_folder_2\\\\zip_3.zip']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also combine multiple lists\n",
    "combined_list = glob.glob(\"sample_input/csv_folder_1/*.csv\") + glob.glob(\"sample_input/csv_folder_2/*.zip\") \n",
    "combined_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839cb4f",
   "metadata": {},
   "source": [
    "## Using os.listdir or glob.glob with regex\n",
    "\n",
    "We can loop through the list and apply regex expressions. To come up with the list to begin with, we can use os.listdir or glob.glob (as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f858abfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20180913_sample_file.csv',\n",
       " '20181022_sample_file.csv',\n",
       " '20190102_sample_file.csv',\n",
       " '20190420_sample_file.csv',\n",
       " '20200211_sample_file.csv',\n",
       " '20200512_sample_file.csv',\n",
       " '20200627_sample_file.csv',\n",
       " '20200711_sample_file.csv',\n",
       " '20200828_sample_file.csv',\n",
       " '20210617_sample_file.csv',\n",
       " '20210801_sample_file.csv',\n",
       " '20220130_sample_file.csv',\n",
       " '20220310_sample_file.csv',\n",
       " '20220608_sample_file.csv',\n",
       " '20220621_sample_file.csv',\n",
       " '20221021_sample_file.csv',\n",
       " '20230128_sample_file.csv',\n",
       " '20230309_sample_file.csv',\n",
       " '20230312_sample_file.csv',\n",
       " '20230425_sample_file.csv',\n",
       " 'diff_file_0.csv',\n",
       " 'diff_file_1.csv',\n",
       " 'diff_file_10.csv',\n",
       " 'diff_file_11.csv',\n",
       " 'diff_file_12.csv',\n",
       " 'diff_file_13.csv',\n",
       " 'diff_file_14.csv',\n",
       " 'diff_file_15.csv',\n",
       " 'diff_file_16.csv',\n",
       " 'diff_file_17.csv',\n",
       " 'diff_file_18.csv',\n",
       " 'diff_file_19.csv',\n",
       " 'diff_file_2.csv',\n",
       " 'diff_file_3.csv',\n",
       " 'diff_file_4.csv',\n",
       " 'diff_file_5.csv',\n",
       " 'diff_file_6.csv',\n",
       " 'diff_file_7.csv',\n",
       " 'diff_file_8.csv',\n",
       " 'diff_file_9.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_list = os.listdir(\"sample_input/csv_folder_1/\")\n",
    "full_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a481b",
   "metadata": {},
   "source": [
    "**Here, we can apply the regex**\n",
    "\n",
    "In this example, we want files that start with 8 numbers, and end in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57c99e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20180913_sample_file.csv',\n",
       " '20181022_sample_file.csv',\n",
       " '20190102_sample_file.csv',\n",
       " '20190420_sample_file.csv',\n",
       " '20200211_sample_file.csv',\n",
       " '20200512_sample_file.csv',\n",
       " '20200627_sample_file.csv',\n",
       " '20200711_sample_file.csv',\n",
       " '20200828_sample_file.csv',\n",
       " '20210617_sample_file.csv',\n",
       " '20210801_sample_file.csv',\n",
       " '20220130_sample_file.csv',\n",
       " '20220310_sample_file.csv',\n",
       " '20220608_sample_file.csv',\n",
       " '20220621_sample_file.csv',\n",
       " '20221021_sample_file.csv',\n",
       " '20230128_sample_file.csv',\n",
       " '20230309_sample_file.csv',\n",
       " '20230312_sample_file.csv',\n",
       " '20230425_sample_file.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'^\\d{8}.*\\.csv$'\n",
    "\n",
    "found_list = [filename for filename in full_list if re.match(pattern, filename)]\n",
    "found_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d741f44",
   "metadata": {},
   "source": [
    "**Note: When using os.listdir, it doesn't give us the filepath, just the file name**. In some circumstances you may want to add the filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0081fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_input/csv_folder_1/20180913_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20181022_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20190102_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20190420_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20200211_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20200512_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20200627_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20200711_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20200828_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20210617_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20210801_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20220130_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20220310_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20220608_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20220621_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20221021_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20230128_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20230309_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20230312_sample_file.csv',\n",
       " 'sample_input/csv_folder_1/20230425_sample_file.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'sample_input/csv_folder_1/{filename}' for filename in found_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acab268",
   "metadata": {},
   "source": [
    "# Read in the files from the list of filepaths and concatenate\n",
    "\n",
    "Once you have a list of filepaths, you can read in the files using pd.read_csv (which also works with .zip files), and then use pd.concat() to combine them into a single pandas dataframe. \n",
    "\n",
    "You can use list comprehension, or you can use a loop. The loop method is great for working with large files (even if the data load is interrupted, you don't lose the work), and you can more easily do further manipulation to the data. \n",
    "\n",
    "It is recommended to load in the file name and time of data load, for downstream data diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15150e",
   "metadata": {},
   "source": [
    "## List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abb72abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_use = combined_list # You can manually provide a list as well\n",
    "\n",
    "combined_table = pd.concat([pd.read_csv(file) for file in list_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6a7d2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>159</td>\n",
       "      <td>center</td>\n",
       "      <td>Drive baby eight.</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>2022-08-13 06:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>870</td>\n",
       "      <td>bed</td>\n",
       "      <td>Someone truth at.</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>2022-09-06 22:36:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>140</td>\n",
       "      <td>they</td>\n",
       "      <td>Husband evening.</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>2023-04-21 13:40:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>360</td>\n",
       "      <td>energy</td>\n",
       "      <td>Also summer.</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>2023-06-11 20:49:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>295</td>\n",
       "      <td>operation</td>\n",
       "      <td>Option set along.</td>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>2022-12-24 03:19:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B          C                  D           E                    F\n",
       "0  48  159     center  Drive baby eight.  2023-04-17  2022-08-13 06:47:34\n",
       "1  69  870        bed  Someone truth at.  2022-11-30  2022-09-06 22:36:01\n",
       "2  88  140       they   Husband evening.  2022-11-18  2023-04-21 13:40:54\n",
       "3  44  360     energy       Also summer.  2022-08-02  2023-06-11 20:49:51\n",
       "4  47  295  operation  Option set along.  2023-06-18  2022-12-24 03:19:13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d9fdc",
   "metadata": {},
   "source": [
    "## Loop\n",
    "\n",
    "With looping, we add additional functions to manipulate the pandas table. (It is possible to do this with list comprehensive, if you define a function instead of using pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54a49f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>filename</th>\n",
       "      <th>load_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>159</td>\n",
       "      <td>center</td>\n",
       "      <td>Drive baby eight.</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>2022-08-13 06:47:34</td>\n",
       "      <td>20180913_sample_file.csv</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>870</td>\n",
       "      <td>bed</td>\n",
       "      <td>Someone truth at.</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>2022-09-06 22:36:01</td>\n",
       "      <td>20180913_sample_file.csv</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>140</td>\n",
       "      <td>they</td>\n",
       "      <td>Husband evening.</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>2023-04-21 13:40:54</td>\n",
       "      <td>20180913_sample_file.csv</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>360</td>\n",
       "      <td>energy</td>\n",
       "      <td>Also summer.</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>2023-06-11 20:49:51</td>\n",
       "      <td>20180913_sample_file.csv</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>295</td>\n",
       "      <td>operation</td>\n",
       "      <td>Option set along.</td>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>2022-12-24 03:19:13</td>\n",
       "      <td>20180913_sample_file.csv</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B          C                  D           E                    F  \\\n",
       "0  48  159     center  Drive baby eight.  2023-04-17  2022-08-13 06:47:34   \n",
       "1  69  870        bed  Someone truth at.  2022-11-30  2022-09-06 22:36:01   \n",
       "2  88  140       they   Husband evening.  2022-11-18  2023-04-21 13:40:54   \n",
       "3  44  360     energy       Also summer.  2022-08-02  2023-06-11 20:49:51   \n",
       "4  47  295  operation  Option set along.  2023-06-18  2022-12-24 03:19:13   \n",
       "\n",
       "                   filename   load_date  \n",
       "0  20180913_sample_file.csv  2023-06-20  \n",
       "1  20180913_sample_file.csv  2023-06-20  \n",
       "2  20180913_sample_file.csv  2023-06-20  \n",
       "3  20180913_sample_file.csv  2023-06-20  \n",
       "4  20180913_sample_file.csv  2023-06-20  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_use = combined_list # You can manually provide a list as well\n",
    "\n",
    "loaded_files = []\n",
    "for file in list_to_use:\n",
    "    this_file = pd.read_csv(file)\n",
    "    \n",
    "    this_file['filename'] = os.path.basename(file) # filename\n",
    "    this_file['load_date'] = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    loaded_files.append(this_file)\n",
    "    \n",
    "# Concatenate\n",
    "combined_table = pd.concat(loaded_files)\n",
    "combined_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54624932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename\n",
       "zip_3.zip                   10000\n",
       "zip_2.zip                   10000\n",
       "zip_1.zip                   10000\n",
       "zip_0.zip                   10000\n",
       "diff_file_19.csv               10\n",
       "diff_file_12.csv               10\n",
       "diff_file_13.csv               10\n",
       "diff_file_14.csv               10\n",
       "diff_file_15.csv               10\n",
       "diff_file_16.csv               10\n",
       "diff_file_17.csv               10\n",
       "diff_file_18.csv               10\n",
       "diff_file_3.csv                10\n",
       "diff_file_2.csv                10\n",
       "20181022_sample_file.csv       10\n",
       "diff_file_4.csv                10\n",
       "diff_file_5.csv                10\n",
       "diff_file_6.csv                10\n",
       "diff_file_7.csv                10\n",
       "diff_file_8.csv                10\n",
       "diff_file_9.csv                10\n",
       "diff_file_11.csv               10\n",
       "20180913_sample_file.csv       10\n",
       "diff_file_1.csv                10\n",
       "20210801_sample_file.csv       10\n",
       "20190102_sample_file.csv       10\n",
       "20190420_sample_file.csv       10\n",
       "20200211_sample_file.csv       10\n",
       "20200512_sample_file.csv       10\n",
       "20200627_sample_file.csv       10\n",
       "20200711_sample_file.csv       10\n",
       "20200828_sample_file.csv       10\n",
       "20210617_sample_file.csv       10\n",
       "20220130_sample_file.csv       10\n",
       "diff_file_0.csv                10\n",
       "20220310_sample_file.csv       10\n",
       "20220608_sample_file.csv       10\n",
       "20220621_sample_file.csv       10\n",
       "20221021_sample_file.csv       10\n",
       "20230128_sample_file.csv       10\n",
       "20230309_sample_file.csv       10\n",
       "20230312_sample_file.csv       10\n",
       "20230425_sample_file.csv       10\n",
       "diff_file_10.csv               10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table['filename'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1985c",
   "metadata": {},
   "source": [
    "# Loading data from URL\n",
    "\n",
    "pandas can load csv from URLs directly. You may have a list of URls to load, and it's done in a similar manner as for a list of file paths.\n",
    "\n",
    "Note: Did you know that pd.read_html can fetch tables from HTML documents? It is useful for webscraping purposes. See the Gryphon template for that if interested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8219313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Effective Date</th>\n",
       "      <th>Exchange Code</th>\n",
       "      <th>Logical Commodity Code</th>\n",
       "      <th>Physical Commodity Code</th>\n",
       "      <th>Contract Name</th>\n",
       "      <th>Currency</th>\n",
       "      <th>New Scanning Range</th>\n",
       "      <th>Previous Scanning Range</th>\n",
       "      <th>New Applied Margin Rate</th>\n",
       "      <th>Previous Applied Margin Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Margin Units</th>\n",
       "      <th>Multiplier</th>\n",
       "      <th>Market</th>\n",
       "      <th>Asset Class</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Spread Reference Product</th>\n",
       "      <th>Position Allocation</th>\n",
       "      <th>Margin Erosion</th>\n",
       "      <th>filename</th>\n",
       "      <th>load_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-APR-23</td>\n",
       "      <td>I</td>\n",
       "      <td>14X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14X-USAC HSFO (Platts) Future</td>\n",
       "      <td>USD</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>5617.2620</td>\n",
       "      <td>5700.7699</td>\n",
       "      <td>...</td>\n",
       "      <td>Lots</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>IFED</td>\n",
       "      <td>Oil</td>\n",
       "      <td>Oil</td>\n",
       "      <td>14X</td>\n",
       "      <td>No</td>\n",
       "      <td>Linear</td>\n",
       "      <td>ENERGY_MARGIN_SCANNING_20230503.CSV</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-APR-23</td>\n",
       "      <td>I</td>\n",
       "      <td>14X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14X-USAC HSFO (Platts) Future</td>\n",
       "      <td>USD</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>6665.0000</td>\n",
       "      <td>6659.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Lots</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>IFED</td>\n",
       "      <td>Oil</td>\n",
       "      <td>Oil</td>\n",
       "      <td>14X</td>\n",
       "      <td>No</td>\n",
       "      <td>Linear</td>\n",
       "      <td>ENERGY_MARGIN_SCANNING_20230503.CSV</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-APR-23</td>\n",
       "      <td>I</td>\n",
       "      <td>14X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14X-USAC HSFO (Platts) Future</td>\n",
       "      <td>USD</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>6348.4125</td>\n",
       "      <td>6350.6883</td>\n",
       "      <td>...</td>\n",
       "      <td>Lots</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>IFED</td>\n",
       "      <td>Oil</td>\n",
       "      <td>Oil</td>\n",
       "      <td>14X</td>\n",
       "      <td>No</td>\n",
       "      <td>Linear</td>\n",
       "      <td>ENERGY_MARGIN_SCANNING_20230503.CSV</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18-APR-23</td>\n",
       "      <td>I</td>\n",
       "      <td>14X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14X-USAC HSFO (Platts) Future</td>\n",
       "      <td>USD</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>5743.2305</td>\n",
       "      <td>5780.6779</td>\n",
       "      <td>...</td>\n",
       "      <td>Lots</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>IFED</td>\n",
       "      <td>Oil</td>\n",
       "      <td>Oil</td>\n",
       "      <td>14X</td>\n",
       "      <td>No</td>\n",
       "      <td>Linear</td>\n",
       "      <td>ENERGY_MARGIN_SCANNING_20230503.CSV</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-APR-23</td>\n",
       "      <td>I</td>\n",
       "      <td>14X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14X-USAC HSFO (Platts) Future</td>\n",
       "      <td>USD</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>5347.3295</td>\n",
       "      <td>5439.0712</td>\n",
       "      <td>...</td>\n",
       "      <td>Lots</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>IFED</td>\n",
       "      <td>Oil</td>\n",
       "      <td>Oil</td>\n",
       "      <td>14X</td>\n",
       "      <td>No</td>\n",
       "      <td>Linear</td>\n",
       "      <td>ENERGY_MARGIN_SCANNING_20230503.CSV</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Effective Date Exchange Code Logical Commodity Code Physical Commodity Code  \\\n",
       "0      18-APR-23             I                    14X                     NaN   \n",
       "1      18-APR-23             I                    14X                     NaN   \n",
       "2      18-APR-23             I                    14X                     NaN   \n",
       "3      18-APR-23             I                    14X                     NaN   \n",
       "4      18-APR-23             I                    14X                     NaN   \n",
       "\n",
       "                   Contract Name Currency  New Scanning Range  \\\n",
       "0  14X-USAC HSFO (Platts) Future      USD              6665.0   \n",
       "1  14X-USAC HSFO (Platts) Future      USD              6665.0   \n",
       "2  14X-USAC HSFO (Platts) Future      USD              6665.0   \n",
       "3  14X-USAC HSFO (Platts) Future      USD              6665.0   \n",
       "4  14X-USAC HSFO (Platts) Future      USD              6665.0   \n",
       "\n",
       "   Previous Scanning Range  New Applied Margin Rate  \\\n",
       "0                   6659.0                5617.2620   \n",
       "1                   6659.0                6665.0000   \n",
       "2                   6659.0                6348.4125   \n",
       "3                   6659.0                5743.2305   \n",
       "4                   6659.0                5347.3295   \n",
       "\n",
       "   Previous Applied Margin Rate  ... Margin Units  Multiplier Market  \\\n",
       "0                     5700.7699  ...         Lots      1000.0   IFED   \n",
       "1                     6659.0000  ...         Lots      1000.0   IFED   \n",
       "2                     6350.6883  ...         Lots      1000.0   IFED   \n",
       "3                     5780.6779  ...         Lots      1000.0   IFED   \n",
       "4                     5439.0712  ...         Lots      1000.0   IFED   \n",
       "\n",
       "  Asset Class  Sector  Spread Reference Product Position Allocation  \\\n",
       "0         Oil     Oil                       14X                  No   \n",
       "1         Oil     Oil                       14X                  No   \n",
       "2         Oil     Oil                       14X                  No   \n",
       "3         Oil     Oil                       14X                  No   \n",
       "4         Oil     Oil                       14X                  No   \n",
       "\n",
       "  Margin Erosion                             filename   load_date  \n",
       "0         Linear  ENERGY_MARGIN_SCANNING_20230503.CSV  2023-06-20  \n",
       "1         Linear  ENERGY_MARGIN_SCANNING_20230503.CSV  2023-06-20  \n",
       "2         Linear  ENERGY_MARGIN_SCANNING_20230503.CSV  2023-06-20  \n",
       "3         Linear  ENERGY_MARGIN_SCANNING_20230503.CSV  2023-06-20  \n",
       "4         Linear  ENERGY_MARGIN_SCANNING_20230503.CSV  2023-06-20  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.theice.com/publicdocs/clear_europe/irmParameters/harmonized\"\n",
    "filenames = [\n",
    "    \"ENERGY_MARGIN_SCANNING_20230503.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230427.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230426.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230424.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230418.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230413.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20230403.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190513.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190509.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190508.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190426.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190412.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190410.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190408.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190401.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190325.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190321.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190319.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190315.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190314.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190305.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190304.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190227.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190225.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190222.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190212.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190208.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190201.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190130.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190125.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190117.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190114.CSV\",\n",
    "    \"ENERGY_MARGIN_SCANNING_20190107.CSV\",\n",
    "]\n",
    "\n",
    "loaded_files = []\n",
    "for file in filenames:\n",
    "    this_file = pd.read_csv(f\"{base_url}/{file}\", storage_options = {'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    this_file['filename'] = os.path.basename(file) # filename\n",
    "    this_file['load_date'] = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    loaded_files.append(this_file)\n",
    "    \n",
    "# Concatenate\n",
    "combined_table = pd.concat(loaded_files)\n",
    "combined_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bba9ef",
   "metadata": {},
   "source": [
    "**Note, we had to add a Header to the URL request, or else we would have been denied access. pd.read_csv let's you use 'storage options' to tailor the HTTP request**\n",
    "\n",
    "Excerpt from https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "Extra options that make sense for a particular storage connection, e.g. host, port, username, password, etc. For HTTP(S) URLs the key-value pairs are forwarded to urllib.request.Request as header options. For other URLs (e.g. starting with “s3://”, and “gcs://”) the key-value pairs are forwarded to fsspec.open. Please see fsspec and urllib for more details, and for more examples on storage options refer here: https://pandas.pydata.org/docs/user_guide/io.html?highlight=storage_options#reading-writing-remote-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc943b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "219px",
    "width": "276px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
